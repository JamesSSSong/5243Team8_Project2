library(shiny)
library(shinythemes)
library(DT)
library(ggplot2)
library(readr)
library(readxl)
library(jsonlite)
library(tools)
library(dplyr)

# User Interface (UI)
ui <- fluidPage(
  theme = shinytheme("flatly"),
  navbarPage(
    "Interactive Data Analysis App",
    
    # 1. Load Datasets
    tabPanel(
      title = "Loading Datasets",
      titlePanel("Loading Datasets"),
      
      sidebarLayout(
        sidebarPanel(
          fileInput("file", "Upload Dataset", accept = c(".csv", ".xlsx", ".json", ".rds")),
          selectInput("dataset", "Or Select a Sample Dataset", choices = c("mtcars", "iris")),
          actionButton("loadData", "Load Data")
        ),
        mainPanel(
          h4("Instructions"),
          p("Upload your dataset or select a sample dataset (e.g., mtcars or iris), then click 'Load Data'."),
          
          tabsetPanel(
            tabPanel("Original Data Preview", DTOutput("originalDataTable"))
          )
        )
      )
    ),
    
    # 3. Data Processing
    tabPanel(
      title = "Data Preprocess",
      titlePanel("Data Preprocess"),
      
      sidebarLayout(
        sidebarPanel(
          h4("Data Cleaning & Preprocessing"),
          
          selectInput("missingStrategy", "Missing Value Strategy", 
                      choices = c("Remove Rows", "Impute Values")),
          
          checkboxInput("removeDuplicates", "Remove Duplicates", value = FALSE),
          
          hr(),
          selectizeInput("scaleCols", "Columns to Scale", 
                         choices = NULL, multiple = TRUE),
          
          hr(),
          selectizeInput("encodeCols", "Categorical Columns to Encode", choices = NULL, multiple = TRUE),
          selectInput("encodingStrategy", "Categorical Encoding Strategy",
                      choices = c("None", "One-Hot Encoding", "Dummy Encoding")),
          
          hr(),
          
          selectInput("outlierStrategy", "Outlier Handling Strategy", 
                      choices = c("None", "Remove Outliers", "Winsorize Outliers")),
          hr(),
          actionButton("processData", "Process Data", class = "btn-primary")
        ),
        
        mainPanel(
          tabsetPanel(
            tabPanel("Data Statistics", verbatimTextOutput("dataSummary")),
            tabPanel("Duplicates", DTOutput("dupTable")),
            tabPanel("Distribution",
                     selectInput("distCol", "Select Column for Impact Analysis", choices = NULL),
                     radioButtons("distPlotType", "Plot Type", choices = c("Histogram", "Boxplot")),
                     plotOutput("distPlot")
                     ),
            tabPanel("Summary", verbatimTextOutput("summaryInfo")),  
            tabPanel("Processed Data", DTOutput("processedDataTable")),
          )
        )
      )
    ),
    
    # 3. Feature Engineering
    tabPanel(
      title = "Feature Engineering",
      titlePanel("Feature Engineering"),
      
      # PCA
      sidebarLayout(
        sidebarPanel(
          h4("PCA (Principal Component Analysis)"),
          selectizeInput("pcaCols", "Select Columns for PCA", choices = NULL, multiple = TRUE),
          numericInput("numPCA", "Number of Principal Components", value = 2, min = 1, max = 10, step = 1),
          actionButton("applyPCA", "Apply PCA", class = "btn-primary"),
          actionButton("savePCA", "Save PCA Result", class = "btn-primary")
        ),
        mainPanel(
          tabsetPanel(
            tabPanel("PCA Summary", verbatimTextOutput("pcaSummary")),
            tabPanel("PCA Transformed Data", DTOutput("pcaDataTable"))
          )
        )
      )
      
      
      ),
      
    # 4. EDA tab
    tabPanel(
      title = "EDA",
      titlePanel("EDA"),
      # Add UI elements for exploratory data analysis here
      
      tabsetPanel(
        tabPanel("Visualization",
                 selectInput("xvar", "X-axis", choices = NULL),
                 selectInput("yvar", "Y-axis", choices = NULL),
                 plotOutput("plot")),
        )
    ),
    
    # About Page
    tabPanel(
      title = "About",
      titlePanel("About"),
      p("This Shiny app is designed for interactive data analysis."),
      p("You can upload your dataset, clean the data, and visualize the results."),
      p("Created with R Shiny, March 2025")
    )
  )
)


# Data Cleaning Function
clean_data <- function(df, missing_strategy = "Remove Rows") {
  df <- df %>% mutate(across(where(is.character), ~ ifelse(. %in% c("?", "N/A", "NaN", "", " "), NA, .)))
  df <- df %>% mutate(across(where(is.character), ~ trimws(.) %>% tolower()))
  df <- df %>% mutate(across(where(is.character), ~ ifelse(grepl("^\\d{4}-\\d{2}-\\d{2}$", .),
                                                           lubridate::ymd(.), .)))
  df <- df %>% mutate(across(where(is.character), ~ ifelse(grepl("^[0-9\\.]+$", .),
                                                           readr::parse_number(.), .)))
  df <- df %>% mutate(across(where(is.character), ~ {if(length(unique(.)) <= 10) {
    factor(.)
  } else {.}
  }))
  
  if(missing_strategy == "Remove Rows") {
    df <- na.omit(df)
  } else if(missing_strategy == "Impute Values") {
    df <- df %>% mutate(across(where(is.numeric), ~ ifelse(is.na(.), median(., na.rm = TRUE), .)))
    df <- df %>% mutate(across(where(is.factor), ~ {
      if(any(is.na(.))) {
        mode_val <- names(sort(table(.), decreasing = TRUE))[1]
        replace(., is.na(.), mode_val)
      } else {.}
    }))
  }
  
  return(df)
}

# Standardization Function
standardize <- function(df, scale_cols) {
  if (!is.null(scale_cols) && length(scale_cols) > 0) {
    df <- df %>% mutate(across(all_of(scale_cols), ~ as.numeric(scale(.))))
  }
  return(df)
}

# Encoding categorical features
encode_categorical <- function(df, encode_cols, strategy = "None") {
  if (!is.null(encode_cols) && length(encode_cols) > 0 && strategy != "None") {
    for (col in encode_cols) {
          if (is.factor(df[[col]])) {
            if(strategy == "One-Hot Encoding") {
              # One-hot encoding
              dummies <- model.matrix(~ . -1, data = df[col])
              dummies <- as.data.frame(dummies)
              df[[col]] <- NULL
              df <- cbind(df, dummies)
            } else if (strategy == "Dummy Encoding") {
              # Dummy encoding
              dummies <- model.matrix(~ . , data = df[col])
              dummies <- as.data.frame(dummies[,-1, drop = FALSE])
              df[[col]] <- NULL
              df <- cbind(df, dummies)
            }
          }
    }
  }
  return(df)
}

# Detect and handle outliers
handle_outliers <- function(df, outlier_strategy = "None") {
  numeric_cols <- names(df)[sapply(df, is.numeric)]
  
  if(outlier_strategy == "Remove Outliers") {
    for(col in numeric_cols) {
      Q1 <- quantile(df[[col]], 0.25, na.rm = TRUE)
      Q3 <- quantile(df[[col]], 0.75, na.rm = TRUE)
      IQR <- Q3 - Q1
      lower_bound <- Q1 - 1.5 * IQR
      upper_bound <- Q3 + 1.5 * IQR
      # Remove rows with outliers
      df <- df %>% filter(df[[col]] >= lower_bound & df[[col]] <= upper_bound)
    }
  } else if(outlier_strategy == "Winsorize Outliers") {
    for(col in numeric_cols) {
      Q1 <- quantile(df[[col]], 0.25, na.rm = TRUE)
      Q3 <- quantile(df[[col]], 0.75, na.rm = TRUE)
      IQR_val <- Q3 - Q1
      lower_bound <- Q1 - 1.5 * IQR_val
      upper_bound <- Q3 + 1.5 * IQR_val
      df[[col]] <- ifelse(df[[col]] < lower_bound, lower_bound,
                          ifelse(df[[col]] > upper_bound, upper_bound, df[[col]]))
    }
  }
  return(df)
}

#PCA
apply_pca <- function(df, pca_cols, n_components) {
  if (!is.null(pca_cols) && length(pca_cols) > 0) {
    pca_model <- prcomp(df[, pca_cols, drop = FALSE], center = TRUE, scale. = TRUE)
    pca_data <- as.data.frame(pca_model$x[, 1:n_components])
    colnames(pca_data) <- paste0("PC", 1:n_components)
    df <- cbind(df, pca_data)
  }
  return(df)
}

# Server Logic
server <- function(input, output, session) {
  origionData <- reactiveVal(NULL)  
  reactiveData <- reactiveVal(NULL)  
  summaryLog <- reactiveVal("No modifications made yet.")
  PCA_transformed_Data<- reactiveVal(NULL)  
  
  # Upload & Read Data
  observeEvent(input$loadData, {
    df <- if (!is.null(input$file)) {
      ext <- tools::file_ext(input$file$name)
      switch(ext,
             csv = read_csv(input$file$datapath),
             xlsx = read_excel(input$file$datapath),
             json = fromJSON(input$file$datapath),
             rds = readRDS(input$file$datapath),
             stop("Invalid file format"))
    } else {
      get(input$dataset)
    }
    
    df <- clean_data(df, missing_strategy = input$missingStrategy)
    
    origionData(df)
    reactiveData(df)
    summaryLog("Data loaded successfully.")
  })
  
  observe({
    df <- reactiveData()
    if (!is.null(df)) {
      updateSelectInput(session, "xvar", choices = names(df)) 
      updateSelectInput(session, "yvar", choices = names(df))
      
      numeric_cols <- names(df)[sapply(df, is.numeric)]
      updateSelectInput(session, "distCol", choices = numeric_cols)
      updateSelectizeInput(session, "scaleCols", choices = numeric_cols, server = TRUE)
      
      categorical_cols <- names(df)[sapply(df, is.factor)]
      updateSelectizeInput(session, "encodeCols", choices = categorical_cols, server = TRUE)
    }
  })
  
  observeEvent(input$processData, {
    req(origionData())
    df <- origionData()
    
    # 1. Remove Duplicates if checked
    if (input$removeDuplicates) {
      num_duplicates <- sum(duplicated(df))
      if (num_duplicates > 0) {
        df <- unique(df)
        summaryLog(paste(summaryLog(), "Removed Duplicates:", num_duplicates))
      } else {
        summaryLog(paste(summaryLog(), "No duplicates found."))
      }
    }
    
    # 2. Scale if user selected columns
    if (!is.null(input$scaleCols) && length(input$scaleCols) > 0) {
      df <- standardize(df, input$scaleCols)
      summaryLog(paste(summaryLog(), "Scaled columns:", paste(input$scaleCols, collapse = ", ")))
    }
    
    # 3. Encode categorical cols if user selected cols & strategy != "None"
    if (!is.null(input$encodeCols) && length(input$encodeCols) > 0 && input$encodingStrategy != "None") {
      df <- encode_categorical(df, input$encodeCols, strategy = input$encodingStrategy)
      summaryLog(paste(summaryLog(), "Encoded columns:", paste(input$encodeCols, collapse = ", "),
                       "Strategy:", input$encodingStrategy))
    }
    
    # 4. Handle Outliers
    if (input$outlierStrategy != "None") {
      df <- handle_outliers(df, 
                            outlier_strategy = input$outlierStrategy)
      summaryLog(paste(summaryLog(), "Outlier Handling:", input$outlierStrategy))
    }
    
    # Update reactiveData
    reactiveData(df)
  })
  
  
  output$originalDataTable <- renderDT({
    req(origionData())
    datatable(origionData())
  })
  
  output$processedDataTable <- renderDT({
    req(reactiveData())
    datatable(reactiveData())
  })
  
  output$summaryInfo <- renderPrint({
    summaryLog()
  })
  
  output$dataSummary <- renderPrint({
    summary(reactiveData())
  })
  
  output$dupTable <- renderDT({
    df <- reactiveData()
    if (!is.null(df)) {
      dup_rows <- df[duplicated(df), ]
      datatable(dup_rows)
    }
  })
  
  output$plot <- renderPlot({
    req(input$xvar, input$yvar) 
    ggplot(reactiveData(), aes_string(x = input$xvar, y = input$yvar)) +
      geom_point() + theme_minimal()
  })
  
  output$distPlot <- renderPlot({
    req(input$distCol, origionData(), reactiveData())
    col <- input$distCol
    
    # Extract the chosen column from both original and processed data
    orig_values <- origionData()[[col]]
    proc_values <- reactiveData()[[col]]
    
    # Build two data frames 
    plot_data_orig <- data.frame(value = orig_values, Dataset = "Original")
    plot_data_proc <- data.frame(value = proc_values, Dataset = "Processed")
    
    # Combine
    plot_data <- rbind(plot_data_orig, plot_data_proc)
    
    if (input$distPlotType == "Histogram") {
      ggplot(plot_data, aes(x = value, fill = Dataset)) +
        geom_histogram(aes(y = ..density..), bins = 30, alpha = 0.5, position = "identity") +
        geom_density(alpha = 0.2) +
        facet_wrap(~Dataset, scales = "free_x") +
        theme_minimal() +
        labs(title = paste("Distribution Impact for", col),
             x = col, y = "Density")
    } else { # boxplot
      ggplot(plot_data, aes(x = Dataset, y = value, fill = Dataset)) +
        geom_boxplot(alpha = 0.5) +
        theme_minimal() +
        labs(title = paste("Boxplot Comparison for", col),
             x = "Dataset", y = col)
    }
  })
  
  #PCA 
  observe({
    df <- reactiveData()
    if (!is.null(df)) {
      numeric_cols <- names(df)[sapply(df, is.numeric)]
      updateSelectizeInput(session, "pcaCols", choices = numeric_cols, server = TRUE)
    }
  })
  

  observeEvent(input$applyPCA, {
    req(reactiveData(), input$pcaCols, input$numPCA)
    df <- reactiveData()
    df <- apply_pca(df, input$pcaCols, input$numPCA)
    PCA_transformed_Data(df)
  })
  

  output$pcaSummary <- renderPrint({
    req(input$pcaCols)
    df <- reactiveData()
    pca_model <- prcomp(df[, input$pcaCols, drop = FALSE], center = TRUE, scale. = TRUE)
    summary(pca_model)
  })
  
  output$pcaDataTable <- renderDT({
    req(PCA_transformed_Data())
    datatable(PCA_transformed_Data(),options = list(scrollX = TRUE))
  })
  
   observeEvent(input$savePCA, {
    df<- PCA_transformed_Data()
    reactiveData(df)
  })
  
}

# Run Shiny App
shinyApp(ui, server)
